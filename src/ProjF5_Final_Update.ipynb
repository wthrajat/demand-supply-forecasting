{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxpO46Ul8qp0",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "## ProjF5 - Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ1RaI13aL_R"
      },
      "source": [
        "* **Please be advised that all models have been re-executed, and as a result, there may be slight variations in the outcomes compared to those presented in the slides.**\n",
        "\n",
        "* **Our models are LSTM+CNN and BiLSTM+CNN**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibqBgqcr8qp3",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-21 12:53:29.334397: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-21 12:53:29.337555: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-21 12:53:29.346313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-21 12:53:29.361051: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-21 12:53:29.365278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-21 12:53:29.377832: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-21 12:53:30.453448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "#Importing all the necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Concatenate, Dense, GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrK750r8qp4",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "### 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB3iJ5Rl8qp4",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "outputId": "1dbf90c2-9266-4936-ba80-eeb6446889ed"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "nGEbxh0VsZez"
      },
      "outputs": [],
      "source": [
        "#Reading data as a DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/NNDL/sales_prediction_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dfT_rZGpsZhk",
        "outputId": "ccc6c88a-189b-4656-c039-ac2b8745ba39"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Ujt0T9sZkO",
        "outputId": "6cf507f8-7bfb-44b1-9366-08839c9c4be7"
      },
      "outputs": [],
      "source": [
        "#Checking for duplicate rows in the dataset\n",
        "print(\"Duplicate rows:\", data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4eOG6U6HsZmm"
      },
      "outputs": [],
      "source": [
        "#Converting 'date' attribute to date type\n",
        "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTRuF7desZpD",
        "outputId": "28ba1a47-9cbc-4c3a-afae-a312173f6839"
      },
      "outputs": [],
      "source": [
        "#Checking for null values in the dataset\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4yXE85lsZra",
        "outputId": "354b6b2f-a526-4609-942d-8c2a7c74f889"
      },
      "outputs": [],
      "source": [
        "#Correlation of each attribute with sales\n",
        "corr = data.corr()\n",
        "corr['sales'].sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HldV9L7slFS"
      },
      "source": [
        "Since none of the attributes individually exhibit a strong correlation with sales, we have decided to include all attributes in the model. By considering them together, we aim to capture potential interactions and dependencies between the attributes, which can contribute to the effectiveness of the model during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "HQ9cGPz9sZuO"
      },
      "outputs": [],
      "source": [
        "'''Sorting the data according to date as it is a time-stamped dataset and it\n",
        "would be convinient for traininig the models on sorted data'''\n",
        "\n",
        "data = data.sort_values('date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0lhP9ghasZwZ",
        "outputId": "87bffcc6-4626-4839-c2fd-da144e902b12"
      },
      "outputs": [],
      "source": [
        "'''It can be seen that all the null values for sales are from 2018-01-01 to\n",
        "2018-03-31 as the goal of the competition, from where this dataset is obtained,\n",
        "is to predict the sales of the stores during this time period using historical\n",
        "data'''\n",
        "\n",
        "data[data['sales'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "YFRzCvkjsZyo"
      },
      "outputs": [],
      "source": [
        "#Storing the rows where sales need to be predicted in y (test set)\n",
        "y = data[data['sales'].isna()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FBc_sY8pstnl",
        "outputId": "9848e069-a907-422f-a1db-487a0abc58a4"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "MHlTpGDDstqC"
      },
      "outputs": [],
      "source": [
        "data = data.drop(y.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsdaRxkpstsh",
        "outputId": "9baed81f-4a62-4cdb-8ee5-06fa8d41270b"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "LGVeQcIQstup"
      },
      "outputs": [],
      "source": [
        "#Storing the rest of the data in X (train set)\n",
        "X = data\n",
        "X = X.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mfvqBCA9sya_",
        "outputId": "9e5aece5-70bc-4674-f0bf-d9b962473e80"
      },
      "outputs": [],
      "source": [
        "#Printing the train set\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "epeLvkq7sydk",
        "outputId": "10d666c5-85c3-43eb-dfee-3563bb5ef65f"
      },
      "outputs": [],
      "source": [
        "#Printing the test set\n",
        "y = y.reset_index(drop=True)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4bKEMcMosyfp",
        "outputId": "1d0aeb6c-4bef-4e7d-9f20-e918b6869616"
      },
      "outputs": [],
      "source": [
        "#Data distribution for each year in train set\n",
        "X['year'] = X['date'].dt.year\n",
        "\n",
        "\n",
        "year_counts = X['year'].value_counts()\n",
        "\n",
        "plt.pie(year_counts, labels=year_counts.index, autopct='%1.1f%%')\n",
        "\n",
        "\n",
        "plt.title('Distribution of Data Values by Year')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7bEzdsws5i7"
      },
      "source": [
        "As we can see, we do not have any data imbalance in the train set. The data is distributed uniformly for each year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6xCmE_u6s24_",
        "outputId": "1524e118-353a-4067-b926-2823d489fd5e"
      },
      "outputs": [],
      "source": [
        "#Bar plot for showing the data distribution in train and test split\n",
        "\n",
        "num_train = X.shape[0]\n",
        "num_test = y.shape[0]\n",
        "\n",
        "plt.bar(['Training Set', 'Test Set'], [num_train, num_test])\n",
        "\n",
        "plt.title('Number of Data Values in Each Set')\n",
        "plt.xlabel('Set')\n",
        "plt.ylabel('Number of Data Values')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K3ISILq8qp5"
      },
      "source": [
        "### 2. Preparing your Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ2woHlHuBX0"
      },
      "source": [
        "#BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "OjTT6eN78qp5"
      },
      "outputs": [],
      "source": [
        "X_bilstm = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "z66mpLfcuOQX",
        "outputId": "8cc0b1c3-f407-4ab6-ee97-6d5174f9f7ff"
      },
      "outputs": [],
      "source": [
        "X_bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "EGQHUwS5uQSn"
      },
      "outputs": [],
      "source": [
        "# Converting 'date' column to ordinal to use it as a feature\n",
        "X_bilstm['date'] = X_bilstm['date'].apply(lambda x: x.toordinal())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XWqAqH_duQVP",
        "outputId": "7be66d4b-c18a-4f24-8cf4-6beb0a67307c"
      },
      "outputs": [],
      "source": [
        "X_bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "iMxzv9EkuQXo"
      },
      "outputs": [],
      "source": [
        "# Dropping 'year' column as it is redundant\n",
        "X_bilstm.drop(columns=['year'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8WXxzsLTuQZ-"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_bilstm[['date', 'store', 'item']] = scaler.fit_transform(X_bilstm[['date', 'store', 'item']])\n",
        "y = scaler.fit_transform(X_bilstm[['sales']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdU82oLOuQcn"
      },
      "outputs": [],
      "source": [
        "# Defining function to create sequences\n",
        "def create_sequences(X, y, time_steps=5):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:(i + time_steps)])\n",
        "        y_seq.append(y[i + time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc00A2zouQe5"
      },
      "outputs": [],
      "source": [
        "# Creating sequences for BiLSTM model\n",
        "X_seq, y_seq = create_sequences(X_bilstm[['date', 'store', 'item']].values, y)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train_bilstm, X_test_bilstm, y_train_bilstm, y_test_bilstm = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMR-4WoMuQg_",
        "outputId": "97e674d6-b121-480e-f3a3-c539211a8bb5"
      },
      "outputs": [],
      "source": [
        "#Using the same number of BiLSTM units as LSTM used in Baseline report for fair comparision\n",
        "\n",
        "bilstm_model = Sequential([\n",
        "    Bidirectional(LSTM(units=50, activation='relu'), input_shape=(X_train_bilstm.shape[1], X_train_bilstm.shape[2])),\n",
        "    Dense(units=1)\n",
        "])\n",
        "bilstm_model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5T6CPD9uQjk",
        "outputId": "2d5a681e-2eaf-4999-c674-ed8396006a0d"
      },
      "outputs": [],
      "source": [
        "# Training the model (using the same epoch and batch size as Baseline for fair comparision)\n",
        "bilstm_model.fit(X_train_bilstm, y_train_bilstm, epochs=25, batch_size=32, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_kt33jLuQlT",
        "outputId": "42a7e8bb-22e2-46bc-90f0-99a36c5410db"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Save the model\n",
        "bilstm_model.save(\"bilstm_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0AtNBuruQnv",
        "outputId": "b9a66456-953d-4147-eb09-75d5ea9c8990"
      },
      "outputs": [],
      "source": [
        "bisltm_model = load_model(\"/content/bilstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UjqwxMxuQpu",
        "outputId": "6a612dcb-b90b-42e9-d4d4-0591e95cd9a3"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "test_loss_bilstm = bisltm_model.evaluate(X_test_bilstm, y_test_bilstm)\n",
        "print(\"Test Loss:\", test_loss_bilstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnhQIQeLuG7t"
      },
      "source": [
        "#LSTM+CNN (Our Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "70TR_9wPuXgf"
      },
      "outputs": [],
      "source": [
        "X_hyb = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cbzYrB0YuXjL"
      },
      "outputs": [],
      "source": [
        "# Converting 'date' column to ordinal to use it as a feature\n",
        "X_hyb['date'] = X_hyb['date'].apply(lambda x: x.toordinal())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RsRPU53BvaaK"
      },
      "outputs": [],
      "source": [
        "# Dropping 'year' column as it is redundant\n",
        "X_hyb.drop(columns=['year'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Q_4Gj-QWLG4R"
      },
      "outputs": [],
      "source": [
        "# # One-hot encode 'store' column\n",
        "# one_hot_encoded = pd.get_dummies(X_hyb['store'], prefix='store')\n",
        "\n",
        "# # Convert True/False to 1/0\n",
        "# one_hot_encoded = one_hot_encoded.astype(int)\n",
        "\n",
        "# # Concatenate one-hot encoded columns to the original DataFrame\n",
        "# X_hyb = pd.concat([X_hyb.drop('store', axis=1), one_hot_encoded], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rXDbsEo7LNxU",
        "outputId": "541d047b-1d56-4d2d-e3d2-b263d0040216"
      },
      "outputs": [],
      "source": [
        "X_hyb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kAKqLUyHuXlb"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_hyb.loc[:, X_hyb.columns != 'sales'] = scaler.fit_transform(X_hyb.loc[:, X_hyb.columns != 'sales'])\n",
        "y = scaler.fit_transform(X_hyb[['sales']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9b3E8enMuXny"
      },
      "outputs": [],
      "source": [
        "# Defining function to create sequences\n",
        "def create_sequences(X, y, time_steps=5):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:(i + time_steps)])\n",
        "        y_seq.append(y[i + time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dOPwzj4yuXp4"
      },
      "outputs": [],
      "source": [
        "# Creating sequences for LSTM+CNN model\n",
        "X_seq, y_seq = create_sequences(X_hyb[['date', 'store', 'item']].values, y)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train_hyb, X_test_hyb, y_train_hyb, y_test_hyb = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B48OkVgNNFR-",
        "outputId": "a9afd32a-ff80-40bb-c999-68ee9b618224"
      },
      "outputs": [],
      "source": [
        "y_train_hyb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnWLJ8NuXvJ",
        "outputId": "b55f145b-6621-4468-de5b-a2768e13acca"
      },
      "outputs": [],
      "source": [
        "# Define input layers for LSTM and CNN models\n",
        "lstm_input = Input(shape=(X_train_hyb.shape[1], X_train_hyb.shape[2]))\n",
        "cnn_input = Input(shape=(X_train_hyb.shape[1], X_train_hyb.shape[2]))\n",
        "\n",
        "# LSTM model\n",
        "lstm_output = LSTM(units=50, activation='relu')(lstm_input)\n",
        "\n",
        "# CNN model\n",
        "cnn_output = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
        "cnn_output = MaxPooling1D(pool_size=2)(cnn_output)\n",
        "cnn_output = Flatten()(cnn_output)\n",
        "\n",
        "# Concatenate the outputs of LSTM and CNN models\n",
        "concatenated = Concatenate()([lstm_output, cnn_output])\n",
        "\n",
        "# Combine with dense layers\n",
        "combined = Dense(64, activation='relu')(concatenated)\n",
        "output = Dense(1)(combined)\n",
        "\n",
        "# Define the ensemble model\n",
        "ensemble_model = Model(inputs=[lstm_input, cnn_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"ensemble_model_checkpoint.h5\", monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = ensemble_model.fit([X_train_hyb, X_train_hyb], y_train_hyb, epochs=50, batch_size=256, validation_data=([X_test_hyb, X_test_hyb], y_test_hyb), callbacks=[early_stopping, checkpoint])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "931OfKg2yPLO"
      },
      "outputs": [],
      "source": [
        "# # Load the best model from checkpoint\n",
        "# from tensorflow.keras.models import load_model\n",
        "# hyb_model = load_model(\"ensemble_model_checkpoint.h5\")\n",
        "# hyb_model.save(\"ensemble_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gj5lFbzvjcK",
        "outputId": "adb66506-d408-4baf-b027-bb17ae22e9b3"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss_ensemble = ensemble_model.evaluate([X_test_hyb, X_test_hyb], y_test_hyb)\n",
        "\n",
        "print(\"Test Loss:\", test_loss_ensemble)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUPmQAS1yrzm"
      },
      "source": [
        "#BiLSTM+CNN (Our Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LChGMNFwyv9b"
      },
      "outputs": [],
      "source": [
        "X_bcnn = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-3iwyMiM1D1O",
        "outputId": "52e26446-88f9-4c92-80b1-7aa3e206cc63"
      },
      "outputs": [],
      "source": [
        "X_bcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Q7ws4WFRyv_-"
      },
      "outputs": [],
      "source": [
        "# Converting 'date' column to ordinal to use it as a feature\n",
        "X_bcnn['date'] = X_bcnn['date'].apply(lambda x: x.toordinal())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GHZQfmS8ywCv"
      },
      "outputs": [],
      "source": [
        "# Dropping 'year' column as it is redundant\n",
        "X_bcnn.drop(columns=['year'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HeiCCn5I2Hzg"
      },
      "outputs": [],
      "source": [
        "# X_encoded = pd.get_dummies(X_gru, columns=['store', 'item'], dtype=int)\n",
        "\n",
        "# # Drop the original 'date' column if you don't need it\n",
        "# X_encoded.drop(columns=['date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b8hNmaWeKfte",
        "outputId": "f6309d71-6680-4a23-ca3e-f9ad95603384"
      },
      "outputs": [],
      "source": [
        "X_bcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "cUSrPBv-ywFF"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = X_bcnn.iloc[:, :-1]\n",
        "\n",
        "X_scaled.iloc[:, :] = scaler.fit_transform(X_scaled)\n",
        "\n",
        "X_bcnn.iloc[:, :-1] = X_scaled\n",
        "y = scaler.fit_transform(X_bcnn[['sales']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2b744p_A2vGj",
        "outputId": "0f165b96-21c9-49a4-ebb2-f4f083c0497f"
      },
      "outputs": [],
      "source": [
        "X_bcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KfUlQHkIy_-s"
      },
      "outputs": [],
      "source": [
        "# Defining function to create sequences\n",
        "def create_sequences(X, y, time_steps=5):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:(i + time_steps)])\n",
        "        y_seq.append(y[i + time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "K93b-sD3zC5H"
      },
      "outputs": [],
      "source": [
        "# Creating sequences for GRU+CNN model\n",
        "X_seq, y_seq = create_sequences(X_bcnn.drop(columns=['sales']).values, y)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train_bcnn, X_test_bcnn, y_train_bcnn, y_test_bcnn = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPiHDxF4zGST",
        "outputId": "6778950f-4058-44fa-c5b2-d2c1ebe7e0e5"
      },
      "outputs": [],
      "source": [
        "# Define input layers for BiLSTM and CNN models\n",
        "bilstm_input = Input(shape=(X_train_bcnn.shape[1], X_train_bcnn.shape[2]))\n",
        "cnn_input = Input(shape=(X_train_bcnn.shape[1], X_train_bcnn.shape[2]))\n",
        "\n",
        "# BiLSTM model\n",
        "lstm_layer = LSTM(units=50, activation='relu')\n",
        "bilstm_output = Bidirectional(lstm_layer)(bilstm_input)\n",
        "\n",
        "# CNN model\n",
        "cnn_output = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
        "cnn_output = MaxPooling1D(pool_size=2)(cnn_output)\n",
        "cnn_output = Flatten()(cnn_output)\n",
        "\n",
        "# Concatenate the outputs of BiLSTM and CNN models\n",
        "concatenated = Concatenate()([bilstm_output, cnn_output])\n",
        "\n",
        "# Combine with dense layers\n",
        "combined = Dense(64, activation='relu')(concatenated)\n",
        "output = Dense(1)(combined)\n",
        "\n",
        "# Define the ensemble model\n",
        "ensemble_model_blstm = Model(inputs=[bilstm_input, cnn_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "ensemble_model_blstm.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"ensemble_model__blstm_checkpoint.h5\", monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = ensemble_model_blstm.fit([X_train_hyb, X_train_hyb], y_train_hyb, epochs=50, batch_size=256, validation_data=([X_test_bcnn, X_test_bcnn], y_test_hyb), callbacks=[early_stopping, checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75LoJeWfzGX8",
        "outputId": "c174cab6-33e9-48ca-c6a5-b8057752f4ce"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss_bilstm = ensemble_model_blstm.evaluate([X_test_bcnn, X_test_bcnn], y_test_bcnn)\n",
        "\n",
        "print(\"Test Loss:\", test_loss_bilstm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofGOo3lM8qp5",
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        }
      },
      "source": [
        "### 3. Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "4hJphdA_CJL8",
        "outputId": "2fae9736-22da-49a4-e1ae-ff9b92bb4b44"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "models = ['BiLSTM', 'LSTM+CNN', 'BiLSTM+CNN']\n",
        "\n",
        "# Train MSE values\n",
        "train_mse = [0.01354, 0.01352, 0.01349]\n",
        "\n",
        "# Test MSE values\n",
        "test_mse = [0.013483, 0.013461, 0.013482]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(models))\n",
        "\n",
        "bars1 = plt.bar(index, train_mse, bar_width, color='blue', label='Train MSE')\n",
        "bars2 = plt.bar(index + bar_width, test_mse, bar_width, color='orange', label='Test MSE')\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.title('Comparison of Train and Test MSE for Different Models')\n",
        "plt.legend()\n",
        "plt.xticks(index + bar_width / 2, models, rotation=45)\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 6), va='bottom', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql6yGkTmmU3d"
      },
      "source": [
        "# BiLSTM+CNN results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JSf3lE0l4V8",
        "outputId": "5292d4f5-9a7a-4346-ebda-4e9c8b272d5d"
      },
      "outputs": [],
      "source": [
        "predicted_values = ensemble_model_blstm.predict([X_test_bcnn, X_test_bcnn])\n",
        "predicted_values_inverse = scaler.inverse_transform(predicted_values)\n",
        "\n",
        "y_test_bcnn_inverse = scaler.inverse_transform(y_test_bcnn)\n",
        "\n",
        "results_df = pd.DataFrame({'Predicted': predicted_values_inverse.flatten(), 'Actual': y_test_bcnn_inverse.flatten()})\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWL9bTtcmZDU"
      },
      "source": [
        "# LSTM+CNN results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6oTPor1mLyF",
        "outputId": "38d6def6-0f20-4aff-b344-7310841e3263"
      },
      "outputs": [],
      "source": [
        "predicted_values = ensemble_model.predict([X_test_hyb, X_test_hyb])\n",
        "predicted_values_inverse = scaler.inverse_transform(predicted_values)\n",
        "\n",
        "y_test_inverse = scaler.inverse_transform(y_test_hyb)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame({'Predicted': predicted_values_inverse.flatten(), 'Actual': y_test_inverse.flatten()})\n",
        "\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
